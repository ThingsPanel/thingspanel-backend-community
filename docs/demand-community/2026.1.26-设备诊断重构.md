# 设备诊断重构

目的
----
在不增加复杂度的前提下重构设备诊断，达到以下目标：
- 与设备调试日志共用同一开关（单一开关控制调试与诊断）。  
- 统计口径与数据库写入粒度一致：按“点位（point）”计数，而不是按“消息”计数。  
- 流程简单直接，遇到错误必须上报并可定位，不做隐藏或模糊化处理。  

核心决策
----
1. 统一开关：复用现有设备调试开关 `tp:devdebug:cfg:{device_id}`，直接使用其 `enabled` 字段控制是否收集调试日志与启用诊断统计（**不新增其他配置字段**）。同一开关同时控制调试日志与诊断。  
2. 统计口径（最小改动原则）：不上新增任何 Redis/接口字段，仍使用现有字段名称（`uplink_total` / `storage_failed` 等），但把 `uplink_total` 的语义从“消息条数”切换为“点位（point）数”（即一条消息包含多个点则增加多次 `uplink_total`）。`storage_failed` 仍表示写入失败的点位数，且只在单条插入真正失败时递增（见下文）。  
3. 错误处理策略（遵循你的要求：简单直接）：不要吞掉错误，遇到写入失败必须记录并上报；但在批量写入失败时**不直接把 batch 的条数累加为失败计数**，仅在逐点插入确实出现单条失败时增加 `storage_failed`。  

简洁流程（关键点）
----
1. 消息接收并解析为点位（在 `uplink` 模块，解析完成并在要写入 DB 之前）。  
2. 在解析后、写入前：对每个点执行 `HINCRBY device:{device_id}:diagnostics:stats uplink_total 1`（注意字段名不变，但语义为点位数）。  
3. 写入 DB（优先批量插入 batchInsert）：
   - 若 `batchInsert` 成功：写入完成，不增加 `storage_failed`。  
   - 若 `batchInsert` 失败：记录一次 `batch insert failed` 日志（含错误摘要），然后尝试逐点插入（fallbackInsert）。**不要在 batchInsert 失败处增加 `storage_failed`**。  
       - 逐点插入时，只有在单条插入确实失败时才执行 `RecordStorageFailed(deviceID, err)`，此操作做两件事：  
         a) `HINCRBY device:{device_id}:diagnostics:stats storage_failed 1`（按失败点位计，字段名不变）；  
         b) LPUSH 到 `device:{device_id}:diagnostics:failures` 记录失败详情（保留最新 N 条）。  
       - 若 fallbackInsert 成功（多数逐点插入最终成功），不把 batch 的失败“虚增”到统计中；仅按真实逐点失败计数。  

Redis Key / 字段（明确，最小改动）
----
- Key: `device:{device_id}:diagnostics:stats`（HASH）字段（字段名保持不变）：  
  - `uplink_total`（int） — 语义调整为“点位总数”（替代之前的消息条数语义）。  
  - `storage_failed`（int） — 语义：写入失败的点位数，仅在单条插入失败时递增。  
  - `downlink_total`（int） — 保持不变。  
  - `downlink_failed`（int） — 保持不变。  
- Key: `device:{device_id}:diagnostics:failures`（LIST） — JSON 失败条目，保留最新 N 条。

API / 前端展示（字段不变）
----
- 接口 `GET /api/devices/{device_id}/diagnostics`：响应结构**不变**（字段名保持原样），但字段含义调整为点位口径：`stats.uplink.total` 的值将表示点位总数，`stats.storage.success` 的计算以 `uplink_total - storage_failed`（点位口径）为准。  
- 前端展示注意点：当 `storage_failed > uplink_total` 时，**不要显示负成功率**，应显示为 0 并明显标注“计数异常：存储失败大于上行点位，请检查日志”。该异常不能被静默，必须在界面或告警中提示并记录时间戳。

日志与告警
----
- 日志：保持原有日志粒度，关键点日志包括：`batch insert failed`（包含 batch size、error 摘要）、`single insert failed`（包含 device_id、point key、error）。日志内容要能定位导致 Timescale 报错的原始 SQL/参数（采样，不要泄露敏感信息）。  
- 告警：若 `storage_failed_points / uplink_points_total > threshold`（例如 5%）并持续 X 分钟，触发告警；若出现 Timescale 特殊错误（如 `invalid INSERT on the root table of hypertable`）要触发高优先级告警并记录采样数据。

兼容与迁移策略（简单直接）
----
1. 兼容写入：重构初期服务端同时写入新字段（`uplink_points_total`、`storage_failed_points`）与旧字段（`uplink_total`、`storage_failed`），前端暂不切换，观测一段时间。  
2. 切换：确认无异常后只读新字段并在 UI 上标注口径变更时间。  
3. 不做历史回填（除非业务强需求），避免复杂离线计算。

测试验收（必须且充足）
----
1. 单消息包含 N 点：发送一条消息，验证 `uplink_points_total` 增加 N，若写入成功则 `storage_failed_points` 不变。  
2. 批量插入成功：确认无 fallback、无单点失败日志。  
3. 批量失败且逐点成功：确认只记录 `batch insert failed` 日志，不把 batch size 计入 `storage_failed_points`。  
4. 单点写入失败：确认 `storage_failed_points` 增加 1，且 `failures` 列表新增对应条目。  

监控与快速排查（运维必备）
----
1. 快速命令（运维用）：  
   - 查看统计：`HGETALL "device:{device_id}:diagnostics:stats"`  
   - 查看失败列表：`LRANGE "device:{device_id}:diagnostics:failures" 0 9`  
2. 在服务端日志中查找关键关键字：`batch insert failed`、`single insert failed`、`invalid INSERT on the root table`。  
3. 对 Timescale 错误要同时抓取当时的 SQL/参数采样以及对应的体积（chunk/ts 值），便于判断是否为表名/触发器/权限/时间列问题。

原则与注意（不要过度设计）
----
1. 开关只有一个：以现有调试开关为准，扩展其配置项以控制诊断；不要新增多开关。  
2. 流程要直观：解析 -> 计点位 -> 批量写入 ->（失败时）逐点重试 -> 仅实失败计入统计；错误必须被记录并可追踪。  
3. 不吞错误：遇到 DB 报错要在日志和 diagnostics fail list 中保留，可选择采样上报给告警/异常平台，但不应静默或“修正”计数。  
4. Fast-path 优化已实现：在 uplink 层按点位计数前会先调用 diagnostics 的快速判断（IsEnabled），若 diagnostics 未启用则跳过逐点计数，避免高并发下的 N 次短路函数调用开销。该优化为轻量判断，不影响功能语义。  

后续工作（可以后续化）
----
- 若你确认本设计，我会把 `td-002` 标为完成并推进下一项（定义 Redis/API/前端变更细节）。  
- 如需我现在生成具体的运维查询/日志 grep 与前端展示样例，我可以继续，但按你要求不做冗余设计，先把这个文档定稿。
